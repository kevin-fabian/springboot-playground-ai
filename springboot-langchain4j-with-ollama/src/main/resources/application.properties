spring.application.name=springboot-langchain4j-with-ollama

langchain4j.ollama.chat-model.base-url=http://localhost:11434
langchain4j.ollama.chat-model.model-name=gemma3n:e4b
langchain4j.ollama.chat-model.temperature=0.1
langchain4j.ollama.chat-model.log-requests=true
langchain4j.ollama.chat-model.log-responses=true


